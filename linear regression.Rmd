---
title: "Linear Regression In R"
author: "Revanth Gullapalli"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
#load necessary libraries
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

# Ensure necessary packages are installed
if (!requireNamespace("ISLR2", quietly = TRUE)) install.packages("ISLR2")
if (!requireNamespace("NHANES", quietly = TRUE)) install.packages("NHANES")

library(ISLR2)
library(NHANES)
##This section loads required libraries and installs missing packages
```



# Boston Dataset Analysis

### Objective

How can we predict the Median Value of Owner_Occupied Homes using the lower Status

\<what are we analyzing? Why? What insight can we gain from this analysis.
#

### Data Understand and preparation

\<What kinds of variables do we have? What kind of questions can we answer further with this data?\>

### Data Loading

\<What does the summary say about this date?\>

```{r load.data}
#load Boston dataset
data(Boston)
glimpse(Boston)

summary(Boston)
#This section loads and summarizes the Boston housing dataset.
```

### Data exploration

```{r missing values}
# Check for missing values
missing_values = Boston %>%
  summarise(across(everything(), ~ sum(is.na(.))))
print(missing_values)
#This step identifies missing values in the dataset.
```
### Train-Test Split

\<How does this technique aid our analysis, especially given new data?\>

```{r train-test}
set.seed(123) # For reproducibility
Boston_split = Boston %>%
  mutate(id = row_number()) %>%
  sample_frac(0.75)

Boston = Boston %>% mutate(id = row_number())

train_data = Boston_split
test_data = anti_join(Boston, Boston_split, by = "id") #Remaining 25%
# The dataset is split into 75% training and 25% testing.
```
### Exploratory Data Analysis

\<what figures did we build?Why? What information do they convey? How it is important to the analysis?\>

```{r histogram for medv}
# Histogram of MEDV 
ggplot(Boston, aes(x = medv)) +
  geom_histogram(fill = "steelblue", binwidth = 2, color = "white") +
  labs(title = "distribution of Median Home Values",
       x = "Median value ($1000s)",
       y = "Count")
#This histogram shows the distribution of median home values.
```
```{r LSTAT vs MEDV Scatterplot}
ggplot(Boston, aes(x = lstat, y=medv)) +
  geom_point(alpha = 0.6, color = 'blue') +
  labs(title = "Scatterplot: LSTAT vs. MEDV",
       x = "Lower Status Population",
       y = "Median Home Value ($1000s)")
```
### Model Implementation & Explanation

\<what model are we using? why does this/these model(s) apply to the data?What are the pros & cons of this type of model? \>

### Perform simple Linear Regression on Training Data

\<Describe the function & model fit. maybe talk about the evaluation metrics?\>

```{r Liunear Regression}
# Perform simple linear regression
lm.fit = lm(medv ~ lstat, data = train_data)
summary(lm.fit)
#This step applies simple linear regression to predict home values using the lower status percentage.
```
Could built a scatter plot with this regression line onto it.

### Apply Model to Test Data

\<could interpret the Test MSE\>

```{r apply model to test_data}
train_mse = mean((train_data$medv - predict(lm.fit, train_data))^2)
test_mse = mean((test_data$medv - predict(lm.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
#Computes Mean Squared Error (MSE) for training and test sets.
```
### Simple Linear Regression results & interpretation

\<Overall, how good is this fit? What does it say about the data and the question being asked?\>

### Perform Multiple Linear Regression on Training Data

\<what question does this model answer?\>

```{r}
lm.multiple.fit = lm(medv ~ lstat + age, data = train_data)  
summary(lm.multiple.fit)
#Performs multiple linear regression with additional predictor variables.
```
### Apply the Model to Test Data

```{r}
train_mse = mean((train_data$medv - predict(lm.multiple.fit, train_data))^2)
test_mse = mean((test_data$medv - predict(lm.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
```
## NHANES Data Analysis

## Objective

#The goal of this project is to predict Body Mass Index (BMI) by exploring three key factors: age, current smoking status, and engagement in physical activity among adults aged 18 to 70.

#1.1 What Are We Examining?

#We are investigating how age, smoking, and physical activity influence BMI. BMI is a widely-used measure of body weight status, and examining these relationships helps us identify important patterns related to lifestyle and health risks.

#1.2 Why Conduct This Analysis?

#An increased BMI is associated with higher risks of various chronic diseases, such as heart disease, hypertension, and type 2 diabetes. Smoking can influence weight through metabolic and appetite-related effects, while physical activity is crucial in managing body weight. Understanding these relationships can help us better grasp how everyday habits and demographic characteristics impact health.

#1.3 Potential Insights

#This analysis aims to reveal how BMI changes with age, assess differences in BMI between smokers and non-smokers, and clarify how physical activity affects weight status. The outcomes could assist in providing targeted health advice and designing effective public health interventions that promote healthy behaviors.

#2. Data Exploration and Preparation

#2.1 Variables Used:

#BMI (Continuous): The primary outcome representing Body Mass Index.

#Age (Continuous): Participants' age, specifically limited to adults aged 18–70.

#SmokeNow (Categorical): Current smoking status (Yes/No).

#PhysActive (Categorical): Physical activity engagement status (Yes/No).

#2.2 Key Questions Addressed:

#How does BMI vary as people age?

#Is there a clear difference in BMI between smokers and non-smokers?

#What relationship exists between physical activity and BMI?

#3. Data Loading and Summary

#We obtained the dataset from the NHANES package, which contains comprehensive health-related data. By summarizing the selected variables (BMI, Age, SmokeNow, PhysActive), we can identify data distributions, detect missing values, and recognize any outliers or inconsistencies. This initial examination ensures data integrity, making our subsequent analysis more robust and reliable.

#please predict BMI using Age, SmokeNow, PhysActive for induviduals between the ages of 18 and 70

## Data understanding & Preparation

## Data loading

```{r}
#install.packages("NHANES")
library(NHANES)
data(NHANES)

SMOKERS = NHANES %>%
  select(BMI, Age, SmokeNow, PhysActive) %>%
  filter(Age >= 18 & Age <= 70)
#Loads and filters NHANES dataset for individuals aged 18-70.
```


## Data Exploration

```{r}
# Check for missing values in the selected data
missing_values <- SMOKERS %>%
  summarise(across(everything(), ~ sum(is.na(.))))

print(missing_values)
```
## Train - Test Split

```{r}
# Set seed for reproducibility
set.seed(123)

# Add the 'id' column to the original dataset (SMOKERS)
SMOKERS <- SMOKERS %>% mutate(id = row_number())

# Split the data into 75% training and 25% testing
SMOKERS_split <- SMOKERS %>%
  sample_frac(0.75)  # 75% for training data

# The remaining 25% will be for testing
test_data <- anti_join(SMOKERS, SMOKERS_split, by = "id")  # Join using 'id' column
train_data <- SMOKERS_split
#Splits the NHANES dataset into training and testing sets.
```

#Splitting the dataset into training (75%) and testing (25%) sets helps us accurately evaluate how well the model performs on new, unseen data. We use the training set to build the model, and the test set to assess its ability to generalize. This method is essential in avoiding overfitting, making sure the model captures genuine trends rather than just memorizing the training data.

## Exploratory Data Analysis

```{r}
# Plot the distribution of BMI
library(ggplot2)

ggplot(SMOKERS, aes(x = BMI)) +
  geom_histogram(fill = "steelblue", binwidth = 5, color = "white") +
  labs(title = "Distribution of BMI", x = "BMI", y = "Count")
```
#In EDA, we use visualizations like histograms, box plots, and scatter plots to assess data distribution, relationships, and patterns, guiding analysis decisions.

## Scatterplot: Age vs. BMI

This helps in visualizing the relationship between **Age** and **BMI**.

```{r}
# Scatterplot: Age vs. BMI
ggplot(SMOKERS, aes(x = Age, y = BMI)) +
  geom_point(alpha = 0.6, color = 'blue') +
  labs(title = "Scatterplot: Age vs. BMI", x = "Age", y = "BMI")
```
# Helps in visualizing the relationship between **Age** and **BMI**.


## Scatterplot: SmokeNow vs. BMI

```{r}
# Scatterplot: SmokeNow vs. BMI
ggplot(SMOKERS, aes(x = SmokeNow, y = BMI)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  labs(title = "Boxplot: SmokeNow vs. BMI", x = "SmokeNow", y = "BMI")
```
#Creating a scatterplot of SmokeNow versus BMI helps us visually examine the relationship between smoking status and body mass index, making it easier to spot any noticeable patterns or correlations.


## Model Implementation

# Used Simple Linear Regression because it effectively predicts a continuous outcome based on the linear relationship with a single predictor variable. This approach is intuitive and computationally efficient, though it can be influenced by outliers and relies heavily on the assumption of linearity.

##Using Simple Linear Regression on the Training Data
#Simple linear regression fits the best possible line to the data by minimizing the squared differences between actual and predicted values. We assess how well the model performs using evaluation metrics such as:

#Mean Squared Error (MSE): Indicates the average squared difference between actual outcomes and model predictions, measuring prediction accuracy.

#R-squared (R²): Reflects the proportion of variance in the target variable that the model successfully explains.

### Perform simple Linear Regression on Training Data

```{r}
#Fit a Simple Linear Regression Model ---
lm.fit <- lm(BMI ~ Age, data = train_data)

# View Model Summary
summary(lm.fit)
#Performs simple linear regression to predict BMI using age.
```
### Apply Model to Text Data

```{r}
train_mse = mean((train_data$BMI - predict(lm.fit, train_data))^2)
test_mse = mean((test_data$BMI - predict(lm.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
#Computes Mean Squared Error for NHANES model.
```
### Simple Linear Regression results & interpretation

#Training MSE: 42.98
The model has an average squared error of 42.98 on the training data, showing a moderate fit to the data.

#Test MSE: 34.98
On the test dataset, the model achieves a slightly lower average squared error of 34.98, indicating it generalizes effectively to new, unseen data.

### Perform Multiple Linear Regression on Training Data

```{r}
lm.multiple.fit = lm(BMI ~ Age + SmokeNow + PhysActive, data = train_data)  
summary(lm.multiple.fit)
#Performs multiple linear regression to predict BMI using multiple factors.
```
### Apply the Model to Test Data

```{r}
train_mse = mean((train_data$BMI - predict(lm.multiple.fit, train_data))^2)
test_mse = mean((test_data$BMI - predict(lm.multiple.fit, test_data))^2)

print(paste("Training MSE:", round(train_mse, 2)))
print(paste("Test MSE:", round(test_mse, 2)))
#Evaluates NHANES multiple linear regression model using MSE.

```
### **Multiple Linear Regression Results & Interpretation*


#Training MSE: 41.57
The average squared error for the training data is 41.57, suggesting the model fits reasonably well but still has potential for improvement.

#Test MSE: 33.69
The model performs even better on the test data, achieving a lower average squared error of 33.69. This indicates good generalization to new, unseen data.

#Conclusion: The Multiple Linear Regression model outperforms the Simple Linear Regression, as indicated by the lower Test MSE. The results demonstrate that the model generalizes effectively without overfitting. Nonetheless, there may be opportunities to further enhance the model by including additional predictor variables or employing more sophisticated modeling techniques.